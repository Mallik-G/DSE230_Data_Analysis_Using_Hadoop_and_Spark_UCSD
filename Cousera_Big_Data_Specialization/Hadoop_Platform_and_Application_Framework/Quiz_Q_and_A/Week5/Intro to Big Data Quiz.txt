
Spark Lesson 1

1. 
Apache Spark was developed in order to provide solutions to shortcomings of another project, and eventually replace it. What is the name of this project?

NO Hadoop

ANSWER MapReduce

HDFS

Pig

2. 
Why is Hadoop MapReduce slow for iterative algorithms?

The Java Virtual Machine uses too much memory

Communication is a bottleneck

ANSWER It needs to read off disk for every iteration

NO Iterative algorithms do not scale well

3. 
What is the most important feature of Apache Spark to speedup iterative algorithms?

Python interface

NO Caching datasets on disk

NO Resiliency to data loss

NO Caching datasets in memory

4. 
Which other Hadoop project can Spark rely to provision and manage the cluster of nodes?

NO HDFS

NO Pig

MapReduce

NO YARN

5. 
When Spark reads data out of HDFS, what is the process that interfaces directly with HDFS?

NO YARN

NO Driver

Cluster Manager

NO Executor

6. 
Under which circumstances is preferable to run Spark in Standalone mode instead of relying on YARN?

Never

ANSWER When you only plan on running Spark jobs

For iterative algorithms

When we want to mix MapReduce and Spark jobs.