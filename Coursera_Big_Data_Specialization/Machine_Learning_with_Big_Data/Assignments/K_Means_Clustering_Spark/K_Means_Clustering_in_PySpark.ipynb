{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Means Clustering in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.57719005617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(count: 48, mean: [ 3.12801059  3.92940785], stdev: [ 2.11814298  2.25624918], max: [ 6.36840832  8.04523732], min: [-1.33872715 -0.32867964])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A script to execute kmeans clustering in spark\n",
    "#to run enter: >>> exec(open(\"./dokmeans.py\").read())\n",
    "\n",
    "import numpy as np\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.clustering import KMeans\n",
    "\n",
    "\n",
    "#generate random data RDD we need this package\n",
    "from pyspark.mllib.random import RandomRDDs\n",
    "\n",
    "#let's generate random class data, add in a cluster center to random 2D points\n",
    "\n",
    "#use default num of partitions, or use a definte number to make it so that the union\n",
    "#  will have samples across clusters\n",
    "c1_v=RandomRDDs.normalVectorRDD(sc,20,2,numPartitions=2,seed=1L).map(lambda v:np.add([1,5],v))\n",
    "c2_v=RandomRDDs.normalVectorRDD(sc,16,2,numPartitions=2,seed=2L).map(lambda v:np.add([5,1],v))\n",
    "c3_v=RandomRDDs.normalVectorRDD(sc,12,2,numPartitions=2,seed=3L).map(lambda v:np.add([4,6],v))\n",
    "\n",
    "#concatenate 2 RDDs with  .union(other) function\n",
    "c12    =c1_v.union(c2_v)\n",
    "my_data=c12.union(c3_v)   #this now has all points, as RDD\n",
    "\n",
    "# k = 1, 9.57719005617\n",
    "# k = 3, 2.09169983811\n",
    "# k = 4, 1.67406692278\n",
    "\n",
    "my_kmmodel = KMeans.train(my_data,k=1,\n",
    "               maxIterations=20,runs=1,\n",
    "               initializationMode='k-means||',seed=10L)\n",
    "\n",
    "#try: help(KMeans.train)  to see parameter options\n",
    "#k is the number of desired clusters.\n",
    "#maxIterations is the maximum number of iterations to run.\n",
    "#initializationMode specifies either random initialization or initialization via k-means||.\n",
    "#runs is the number of times to run the k-means algorithm (k-means is not guaranteed to find a globally optimal solution, and when run multiple times on a given dataset, the algorithm returns the best clustering result).\n",
    "#initializationSteps determines the number of steps in the k-means|| algorithm.\n",
    "#epsilon determines the distance threshold within which we consider k-means to have converged.\n",
    " \n",
    "\n",
    "#type dir(my_kmmodel) to see functions available on the cluster results object\n",
    "\n",
    "#The computeCost function might not be available on your cloudera vm,\n",
    "#  spark mlllib, it computes the Sum Squared Error: my_kmmodel.computeCost(my_data)  \n",
    "\n",
    "#This does the same thing as computeCost, and gives an example of coding a metric\n",
    "#get sse of a point to the center of the cluster it's assigned to\n",
    "def getsse(point):\n",
    "    this_center = my_kmmodel.centers[my_kmmodel.predict(point)]\n",
    "           #for this point get it's clustercenter\n",
    "    return (sum([x**2 for x in (point - this_center)])) \n",
    "\n",
    "\n",
    "my_sse=my_data.map(getsse).collect()  #collect list of sse of each pt to its center\n",
    "print np.array(my_sse).mean()      \n",
    " \n",
    "my_data.stats()\n",
    "# k = 4\n",
    "# (count: 48, mean: [ 3.12801059  3.92940785], \n",
    "# stdev: [ 2.11814298  2.25624918], max: [ 6.36840832  8.04523732], min: [-1.33872715 -0.32867964])\n",
    "\n",
    "\n",
    "\n",
    "# k = 3 \n",
    "# (count: 48, mean: [ 3.12801059  3.92940785], \n",
    "# stdev: [ 2.11814298  2.25624918], max: [ 6.36840832  8.04523732], min: [-1.33872715 -0.32867964])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
